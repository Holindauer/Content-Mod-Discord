{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Test on Unseen Data\n",
    "I have just completed finetuning of this model on sagemaker. In this notebook I am conducting a test of the model on data it has not see yet.\n",
    "\n",
    "The accuracy result on the unseen data was: 97%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in fine tuned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig, DistilBertForSequenceClassification\n",
    "\n",
    "num_labels=2\n",
    "\n",
    "config = DistilBertConfig.from_pretrained('/home/ec2-user/SageMaker/RAC_training_sagemaker/model', num_labels=num_labels)\n",
    "model = DistilBertForSequenceClassification.from_pretrained('/home/ec2-user/SageMaker/RAC_training_sagemaker/model', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval of Model\n",
    "I am going to perform a quick evaluation of the model here. The final eval acc of the model on the wikipedia toxic comments test datset during training was 0.96832. I had mistakenly used the test set for eval during training so here I will use the validation set to test the model.\n",
    "\n",
    "Below I load in the tokenizer I used on the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "model_path = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\n\\nI know you are (an independent). That was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Or a big shot book critic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh - and the template's tone is not appropriat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For ex. If Warriors envade the Philippine isla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\n\\nand who is that \"\"someone\"\" that you are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic\n",
       "0  \"\\n\\nI know you are (an independent). That was...      0\n",
       "1                         Or a big shot book critic?      0\n",
       "2  Oh - and the template's tone is not appropriat...      0\n",
       "3  For ex. If Warriors envade the Philippine isla...      0\n",
       "4  \"\\n\\nand who is that \"\"someone\"\" that you are ...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val_set = pd.read_csv('/home/ec2-user/SageMaker/RAC_training_sagemaker/cursory_data_prep/processed_val.csv')\n",
    "\n",
    "val_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below functions are used to tokenize/encode text data into the format necessary for input to distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "def encode(comment, label):\n",
    "    encoded = tokenizer(comment, truncation=True, padding='max_length', max_length=128, return_tensors=\"pt\")\n",
    "    \n",
    "    # Convert 0d tensors to python numbers using .item() for each element in vector\n",
    "    attention_mask = [i.item() for i in encoded['attention_mask'][0]]\n",
    "    input_ids = [i.item() for i in encoded['input_ids'][0]]\n",
    "    label = label.item() if isinstance(label, torch.Tensor) else label\n",
    "    \n",
    "    # Return data in a dictionary format\n",
    "    return {\n",
    "        'attention_mask': attention_mask,\n",
    "        'input_ids': input_ids,\n",
    "        'label': label,\n",
    "        'text': comment\n",
    "    }\n",
    "\n",
    "def transform_to_dataframe(df):\n",
    "    # Apply the encode function to each row of the dataframe\n",
    "    encoded_data = df.apply(lambda row: encode(row['comment_text'], row['toxic']), axis=1)\n",
    "    \n",
    "    # Convert encoded data to a list of dictionaries\n",
    "    list_of_dicts = [item for item in encoded_data]\n",
    "    \n",
    "    # Convert list of dictionaries to dataframe\n",
    "    return pd.DataFrame(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/RAC_training_sagemaker'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1000, 1045, 2113, 2017, 2024, 1006, 2019...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\\n\\nI know you are (an independent). That was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[101, 2030, 1037, 2502, 2915, 2338, 6232, 1029...</td>\n",
       "      <td>0</td>\n",
       "      <td>Or a big shot book critic?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 2821, 1011, 1998, 1996, 23561, 1005, 105...</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh - and the template's tone is not appropriat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 2005, 4654, 1012, 2065, 6424, 4372, 3567...</td>\n",
       "      <td>0</td>\n",
       "      <td>For ex. If Warriors envade the Philippine isla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1000, 1998, 2040, 2003, 2008, 1000, 1000...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\\n\\nand who is that \"\"someone\"\" that you are ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                           input_ids  label  \\\n",
       "0  [101, 1000, 1045, 2113, 2017, 2024, 1006, 2019...      0   \n",
       "1  [101, 2030, 1037, 2502, 2915, 2338, 6232, 1029...      0   \n",
       "2  [101, 2821, 1011, 1998, 1996, 23561, 1005, 105...      0   \n",
       "3  [101, 2005, 4654, 1012, 2065, 6424, 4372, 3567...      0   \n",
       "4  [101, 1000, 1998, 2040, 2003, 2008, 1000, 1000...      0   \n",
       "\n",
       "                                                text  \n",
       "0  \"\\n\\nI know you are (an independent). That was...  \n",
       "1                         Or a big shot book critic?  \n",
       "2  Oh - and the template's tone is not appropriat...  \n",
       "3  For ex. If Warriors envade the Philippine isla...  \n",
       "4  \"\\n\\nand who is that \"\"someone\"\" that you are ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val_set = transform_to_dataframe(val_set)\n",
    "encoded_val_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference \n",
    "Below I am pasing the encoded data into the model for inference after converting it to torch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "There are 192 batches\n",
      "batch 0 completed\n",
      "batch 25 completed\n",
      "batch 50 completed\n",
      "batch 75 completed\n",
      "batch 100 completed\n",
      "batch 125 completed\n",
      "batch 150 completed\n",
      "batch 175 completed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Convert 'input_ids' and 'attention_mask' columns to tensors\n",
    "input_ids = torch.tensor(encoded_val_set['input_ids'].tolist())\n",
    "attention_mask = torch.tensor(encoded_val_set['attention_mask'].tolist())\n",
    "\n",
    "# Move the model to GPU\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "batch_size = 128  #memory issues when ran whole batch on 1 gpu\n",
    "num_batches = len(input_ids) // batch_size + (len(input_ids) % batch_size != 0)\n",
    "print(f'There are {num_batches} batches')\n",
    "\n",
    "all_predicted_labels = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    if i % 25 == 0:\n",
    "        print(f'batch {i} completed')\n",
    "    batch_input_ids = input_ids[i*batch_size:(i+1)*batch_size].to(device)\n",
    "    batch_attention_mask = attention_mask[i*batch_size:(i+1)*batch_size].to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        # Depending on the model, it might return a tuple. \n",
    "        # Typically, the first entry in the tuple is the output logits.\n",
    "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        logits = outputs[0]\n",
    "        # Use the argmax function to get the predicted labels for the current batch\n",
    "        predicted_labels = torch.argmax(logits, dim=1).cpu()\n",
    "        all_predicted_labels.append(predicted_labels)\n",
    "\n",
    "# Concatenate all the predicted labels\n",
    "all_predicted_labels = torch.cat(all_predicted_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9700459891742298\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(predicted_labels, val_set):\n",
    "    correct = 0\n",
    "    true_labels = val_set['label'].tolist()  # Assuming 'label' is the column name with true labels\n",
    "    \n",
    "    for i in range(len(true_labels)):\n",
    "        if predicted_labels[i].item() == true_labels[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    return correct/len(true_labels)\n",
    "\n",
    "acc = check_accuracy(all_predicted_labels, encoded_val_set)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice 97% accuracy\n",
    "\n",
    "Let's also measure the precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8825, Recall: 0.8058\n"
     ]
    }
   ],
   "source": [
    "def precision_recall(predicted_labels, val_set):\n",
    "    TP = 0  # True Positives\n",
    "    FP = 0  # False Positives\n",
    "    FN = 0  # False Negatives\n",
    "    true_labels = val_set['label'].tolist()  # Assuming 'label' is the column name with true labels\n",
    "    \n",
    "    for i in range(len(true_labels)):\n",
    "        if predicted_labels[i].item() == true_labels[i] == 1:  # Assuming positive class is labeled as '1'\n",
    "            TP += 1\n",
    "        elif predicted_labels[i].item() == 1 and true_labels[i] == 0:\n",
    "            FP += 1\n",
    "        elif predicted_labels[i].item() == 0 and true_labels[i] == 1:\n",
    "            FN += 1\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "prec, rec = precision_recall(all_predicted_labels, encoded_val_set)\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
